{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"PokeGan.ipynb","version":"0.3.2","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"U-f2LOy0E5S0","colab_type":"code","outputId":"10834eae-caa4-4aab-a0b8-67fe29710862","executionInfo":{"status":"ok","timestamp":1567965029513,"user_tz":-330,"elapsed":25283,"user":{"displayName":"Subhaditya Mukherjee","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mB5ARHorU2gC7hfIA8xplQXP5ATfspoFizWCAXQjR0=s64","userId":"10930596869852951720"}},"colab":{"base_uri":"https://localhost:8080/","height":122}},"source":["from google.colab import drive\n","drive.mount('/content/drive')\n"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n","\n","Enter your authorization code:\n","··········\n","Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"T8Kvsuy0FIpO","colab_type":"code","colab":{}},"source":["# %cd /gdrive/My Drive/Colab_ML/PokeGan\n","# !git clone https://github.com/moxiegushi/pokeGAN"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"DJ00VIH7FIu4","colab_type":"code","outputId":"58bf35ec-0973-4528-b4bf-89018e8a1def","executionInfo":{"status":"ok","timestamp":1567965033697,"user_tz":-330,"elapsed":29438,"user":{"displayName":"Subhaditya Mukherjee","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mB5ARHorU2gC7hfIA8xplQXP5ATfspoFizWCAXQjR0=s64","userId":"10930596869852951720"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["import os\n","import tensorflow as tf\n","import numpy as np\n","import cv2\n","import random \n","import scipy\n","%cd \"/content/drive/My Drive/Colab_ML/PokeGan\"\n","%pwd\n","from utils import *\n","import datetime"],"execution_count":3,"outputs":[{"output_type":"stream","text":["/content/drive/My Drive/Colab_ML/PokeGan\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"db5vsGf8FIxw","colab_type":"code","colab":{}},"source":["slim = tf.contrib.slim\n","\n","HEIGHT, WIDTH, CHANNEL = 128,128,3\n","BATCH_SIZE = 64\n","EPOCH = 5000\n","\n","version = 'newPokemon'\n","newPoke_path = '/content/drive/My Drive/Colab_ML/PokeGan/'+version"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"yV3iYbcBFI0R","colab_type":"code","colab":{}},"source":["def lrelu(x,n,leak = 0.2):\n","    return tf.maximum(x,leak*x,name = n)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"6DaOGw0CFI3C","colab_type":"code","colab":{}},"source":["def process_data():\n","    current_dir = os.getcwd()\n","    pokemon_dir = os.path.join(current_dir, 'data')\n","    images = []\n","    for each in os.listdir(pokemon_dir):\n","        images.append(os.path.join(pokemon_dir, each))\n","    \n","    all_images = tf.convert_to_tensor(images, dtype = tf.string)\n","\n","    images_queue = tf.train.slice_input_producer([all_images])\n","    content = tf.read_file(images_queue[0])\n","    image = tf.image.decode_jpeg(content,channels = CHANNEL)\n","\n","    image = tf.image.random_flip_left_right(image)\n","    image = tf.image.random_brightness(image , max_delta = 0.1)\n","    image = tf.image.random_contrast(image, lower = 0.9, upper = 1.1)\n","\n","    size = [HEIGHT, WIDTH]\n","    image = tf.image.resize_images(image, size)\n","    image.set_shape([HEIGHT, WIDTH, CHANNEL])\n","    image = tf.cast(image, tf.float32)\n","\n","    image = image/255.0\n","\n","    images_batch = tf.train.shuffle_batch([image],batch_size=BATCH_SIZE, num_threads = 4, capacity = 200+3*BATCH_SIZE, min_after_dequeue = 200)\n","    num_images = len(images)\n","\n","    return images_batch, num_images"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"yFWUCObYFI5z","colab_type":"code","colab":{}},"source":["def generator(input, random_dim, is_train, reuse=False):\n","    print('Gene')\n","    c4, c8, c16, c32, c64 = 512, 256, 128, 64, 32 # channel num\n","    s4 = 4\n","    output_dim = CHANNEL  # RGB image\n","    with tf.variable_scope('gen') as scope:\n","        if reuse:\n","            scope.reuse_variables()\n","        w1 = tf.get_variable('w1', shape=[random_dim, s4 * s4 * c4], dtype=tf.float32,\n","                             initializer=tf.truncated_normal_initializer(stddev=0.02))\n","        b1 = tf.get_variable('b1', shape=[c4 * s4 * s4], dtype=tf.float32,\n","                             initializer=tf.constant_initializer(0.0))\n","        flat_conv1 = tf.add(tf.matmul(input, w1), b1, name='flat_conv1')\n","        # 4*4*512\n","        conv1 = tf.reshape(flat_conv1, shape=[-1, s4, s4, c4], name='conv1')\n","        bn1 = tf.contrib.layers.batch_norm(conv1, is_training=is_train, epsilon=1e-5, decay = 0.9,  updates_collections=None, scope='bn1')\n","        act1 = tf.nn.relu(bn1, name='act1')\n","        # 8*8*256\n","        conv2 = tf.layers.conv2d_transpose(act1, c8, kernel_size=[5, 5], strides=[2, 2], padding=\"SAME\",\n","                                           kernel_initializer=tf.truncated_normal_initializer(stddev=0.02),\n","                                           name='conv2')\n","        bn2 = tf.contrib.layers.batch_norm(conv2, is_training=is_train, epsilon=1e-5, decay = 0.9,  updates_collections=None, scope='bn2')\n","        act2 = tf.nn.relu(bn2, name='act2')\n","        # 16*16*128\n","        conv3 = tf.layers.conv2d_transpose(act2, c16, kernel_size=[5, 5], strides=[2, 2], padding=\"SAME\",\n","                                           kernel_initializer=tf.truncated_normal_initializer(stddev=0.02),\n","                                           name='conv3')\n","        bn3 = tf.contrib.layers.batch_norm(conv3, is_training=is_train, epsilon=1e-5, decay = 0.9,  updates_collections=None, scope='bn3')\n","        act3 = tf.nn.relu(bn3, name='act3')\n","        # 32*32*64\n","        \n","        \n","        conv4 = tf.layers.conv2d_transpose(act3, c32, kernel_size=[5, 5], strides=[2, 2], padding=\"SAME\",\n","                                           kernel_initializer=tf.truncated_normal_initializer(stddev=0.02),\n","                                           name='conv4')\n","        bn4 = tf.contrib.layers.batch_norm(conv4, is_training=is_train, epsilon=1e-5, decay = 0.9,  updates_collections=None, scope='bn4')\n","        act4 = tf.nn.relu(bn4, name='act4')\n","        # 64*64*32\n","        \n","        conv5 = tf.layers.conv2d_transpose(act4, c64, kernel_size=[5, 5], strides=[2, 2], padding=\"SAME\",\n","                                           kernel_initializer=tf.truncated_normal_initializer(stddev=0.02),\n","                                           name='conv5')\n","        bn5 = tf.contrib.layers.batch_norm(conv5, is_training=is_train, epsilon=1e-5, decay = 0.9,  updates_collections=None, scope='bn5')\n","        act5 = tf.nn.relu(bn5, name='act5')\n","        \n","        #128*128*3\n","        conv6 = tf.layers.conv2d_transpose(act5, output_dim, kernel_size=[5, 5], strides=[2, 2], padding=\"SAME\",\n","                                           kernel_initializer=tf.truncated_normal_initializer(stddev=0.02),\n","                                           name='conv6')\n","        # bn6 = tf.contrib.layers.batch_norm(conv6, is_training=is_train, epsilon=1e-5, decay = 0.9,  updates_collections=None, scope='bn6')\n","        act6 = tf.nn.tanh(conv6, name='act6')\n","        return act6"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"k8nIqkrDFI84","colab_type":"code","colab":{}},"source":["def discriminator(input, is_train, reuse=False):\n","    print('Disc')\n","    c2, c4, c8, c16 = 64, 128, 256, 51\n","    with tf.variable_scope('dis') as scope:\n","        if reuse:\n","            scope.reuse_variables()\n","        conv1 = tf.layers.conv2d(input, c2, kernel_size=[5, 5], strides=[2, 2], padding=\"SAME\",\n","                                 kernel_initializer=tf.truncated_normal_initializer(stddev=0.02),\n","                                 name='conv1')\n","        act1 = lrelu(conv1, n='act1')\n","        conv2 = tf.layers.conv2d(act1, c4, kernel_size=[5, 5], strides=[2, 2], padding=\"SAME\",\n","                                 kernel_initializer=tf.truncated_normal_initializer(stddev=0.02),\n","                                 name='conv2')\n","        bn2 = tf.contrib.layers.batch_norm(conv2, is_training=is_train, epsilon=1e-5, decay = 0.9,  updates_collections=None, scope='bn2')\n","        act2 = lrelu(bn2, n='act2')\n","        \n","        \n","        conv3 = tf.layers.conv2d(act2, c8, kernel_size=[5, 5], strides=[2, 2], padding=\"SAME\",\n","                                 kernel_initializer=tf.truncated_normal_initializer(stddev=0.02),\n","                                 name='conv3')\n","        bn3 = tf.contrib.layers.batch_norm(conv3, is_training=is_train, epsilon=1e-5, decay = 0.9,  updates_collections=None, scope='bn3')\n","        act3 = lrelu(bn3, n='act3')\n","        \n","        \n","        conv4 = tf.layers.conv2d(act3, c16, kernel_size=[5, 5], strides=[2, 2], padding=\"SAME\",\n","                                 kernel_initializer=tf.truncated_normal_initializer(stddev=0.02),\n","                                 name='conv4')\n","        bn4 = tf.contrib.layers.batch_norm(conv4, is_training=is_train, epsilon=1e-5, decay = 0.9,  updates_collections=None, scope='bn4')\n","        act4 = lrelu(bn4, n='act4')\n","                \n","                \n","        \n","        dim = int(np.prod(act4.get_shape()[1:]))\n","        fc1 = tf.reshape(act4, shape=[-1, dim], name='fc1')\n","        \n","        w2 = tf.get_variable('w2', shape=[fc1.shape[-1], 1], dtype=tf.float32,\n","                             initializer=tf.truncated_normal_initializer(stddev=0.02))\n","        b2 = tf.get_variable('b2', shape=[1], dtype=tf.float32,\n","                             initializer=tf.constant_initializer(0.0))\n","\n","        \n","        logits = tf.add(tf.matmul(fc1, w2), b2, name='logits')\n","        \n","        acted_out = tf.nn.sigmoid(logits)\n","        return logits \n","\n","\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"N4dYf6jYFJAX","colab_type":"code","colab":{}},"source":["def train():\n","\n","    random_dim = 100\n","\n","    \n","    with tf.variable_scope('input'):\n","        real_image = tf.placeholder(tf.float32, shape = [None, HEIGHT, WIDTH, CHANNEL], name='real_image')\n","        random_input = tf.placeholder(tf.float32, shape=[None, random_dim], name='rand_input')\n","        is_train = tf.placeholder(tf.bool, name='is_train')\n","    \n","\n","    fake_image = generator(random_input, random_dim, is_train)\n","    real_result = discriminator(real_image, is_train)\n","    fake_result = discriminator(fake_image, is_train, reuse=True)\n","    \n","    d_loss = tf.reduce_mean(fake_result) - tf.reduce_mean(real_result)\n","    g_loss = -tf.reduce_mean(fake_result) \n","\n","\n","    t_vars = tf.trainable_variables()\n","    d_vars = [var for var in t_vars if 'dis' in var.name]\n","    g_vars = [var for var in t_vars if 'gen' in var.name]\n","\n","\n","    trainer_d = tf.train.RMSPropOptimizer(learning_rate=2e-4).minimize(d_loss, var_list=d_vars)\n","    trainer_g = tf.train.RMSPropOptimizer(learning_rate=2e-4).minimize(g_loss, var_list=g_vars)\n","\n","    d_clip = [v.assign(tf.clip_by_value(v, -0.01, 0.01)) for v in d_vars]\n","\n","    \n","    batch_size = BATCH_SIZE\n","    image_batch, samples_num = process_data()\n","    \n","    batch_num = int(samples_num / batch_size)\n","    total_batch = 0\n","    sess = tf.Session()\n","    saver = tf.train.Saver()\n","    sess.run(tf.global_variables_initializer())\n","    sess.run(tf.local_variables_initializer())\n","    ckpt = tf.train.latest_checkpoint('/content/drive/My Drive/Colab_ML/PokeGan/model/' + version)\n","    try:\n","        print('[INFO] RESTORED')\n","        saver.restore(sess, ckpt)\n","        \n","\n","\n","    except:\n","        pass\n","    coord = tf.train.Coordinator()\n","    threads = tf.train.start_queue_runners(sess=sess, coord=coord)\n","\n","    print ('total training sample num:%d' % samples_num)\n","    print ('batch size: %d, batch num per epoch: %d, epoch num: %d' % (batch_size, batch_num, EPOCH))\n","    print ('start training...')\n","    for i in range(1950,EPOCH):\n","        print('epochh')\n","        for j in range(batch_num):\n","            print('batch')\n","            d_iters = 5\n","            g_iters = 1\n","\n","            train_noise = np.random.uniform(-1.0, 1.0, size=[batch_size, random_dim]).astype(np.float32)\n","            for k in range(d_iters):\n","                train_image = sess.run(image_batch)\n","                sess.run(d_clip)\n","                \n","                _, dLoss = sess.run([trainer_d, d_loss],\n","                                    feed_dict={random_input: train_noise, real_image: train_image, is_train: True})\n","\n","            for k in range(g_iters):\n","                _, gLoss = sess.run([trainer_g, g_loss],\n","                                    feed_dict={random_input: train_noise, is_train: True})\n","\n","            \n","\n","        if i%50 == 0:\n","            with open('/content/drive/My Drive/Colab_ML/PokeGan/saverfile.txt','a+') as f:\n","                f.write('Saving image and model at {}\\n'.format(str(datetime.datetime.now())))\n","            if not os.path.exists('/content/drive/My Drive/Colab_ML/PokeGan/model/' + version):\n","                os.makedirs('/content/drive/My Drive/Colab_ML/PokeGan/model/' + version)\n","            saver.save(sess, '/content/drive/My Drive/Colab_ML/PokeGan/model/' +version + '/' + str(i)) \n","            if not os.path.exists(newPoke_path):\n","                os.makedirs(newPoke_path)\n","            sample_noise = np.random.uniform(-1.0, 1.0, size=[batch_size, random_dim]).astype(np.float32)\n","            imgtest = sess.run(fake_image, feed_dict={random_input: sample_noise, is_train: False})\n","            save_images(imgtest, [8,8] ,newPoke_path + '/epoch' + str(i) + '.jpg')\n","            \n","        print ('train:[%d],d_loss:%f,g_loss:%f' % (i, dLoss, gLoss))\n","    coord.request_stop()\n","    coord.join(threads)\n","\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"TsxKXIgWBrpA","colab_type":"code","outputId":"b3fde8cf-9f22-4730-b9fb-2acf1d1d5414","executionInfo":{"status":"ok","timestamp":1567965034931,"user_tz":-330,"elapsed":30447,"user":{"displayName":"Subhaditya Mukherjee","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mB5ARHorU2gC7hfIA8xplQXP5ATfspoFizWCAXQjR0=s64","userId":"10930596869852951720"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["device_name = tf.test.gpu_device_name()\n","device_name"],"execution_count":10,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'/device:GPU:0'"]},"metadata":{"tags":[]},"execution_count":10}]},{"cell_type":"code","metadata":{"id":"mUb402eBOWnw","colab_type":"code","outputId":"0711df42-0fd6-4a1e-c446-562cb3e6a70b","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"error","timestamp":1567967660370,"user_tz":-330,"elapsed":865,"user":{"displayName":"Subhaditya Mukherjee","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mB5ARHorU2gC7hfIA8xplQXP5ATfspoFizWCAXQjR0=s64","userId":"10930596869852951720"}}},"source":["if __name__==\"__main__\":\n","\n","    train()"],"execution_count":11,"outputs":[{"output_type":"stream","text":["Gene\n","WARNING:tensorflow:From <ipython-input-7-22561fe95683>:21: conv2d_transpose (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use `tf.keras.layers.Conv2DTranspose` instead.\n","Disc\n","WARNING:tensorflow:From <ipython-input-8-9173a3f1325a>:9: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use `tf.keras.layers.Conv2D` instead.\n","Disc\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use tf.where in 2.0, which has the same broadcast rule as np.where\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/rmsprop.py:119: calling Ones.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Call initializer instance with the dtype argument instead of passing it to the constructor\n","WARNING:tensorflow:From <ipython-input-6-6bb16eb19fc0>:10: slice_input_producer (from tensorflow.python.training.input) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Queue-based input pipelines have been replaced by `tf.data`. Use `tf.data.Dataset.from_tensor_slices(tuple(tensor_list)).shuffle(tf.shape(input_tensor, out_type=tf.int64)[0]).repeat(num_epochs)`. If `shuffle=False`, omit the `.shuffle(...)`.\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/input.py:374: range_input_producer (from tensorflow.python.training.input) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Queue-based input pipelines have been replaced by `tf.data`. Use `tf.data.Dataset.range(limit).shuffle(limit).repeat(num_epochs)`. If `shuffle=False`, omit the `.shuffle(...)`.\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/input.py:320: input_producer (from tensorflow.python.training.input) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Queue-based input pipelines have been replaced by `tf.data`. Use `tf.data.Dataset.from_tensor_slices(input_tensor).shuffle(tf.shape(input_tensor, out_type=tf.int64)[0]).repeat(num_epochs)`. If `shuffle=False`, omit the `.shuffle(...)`.\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/input.py:190: limit_epochs (from tensorflow.python.training.input) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Queue-based input pipelines have been replaced by `tf.data`. Use `tf.data.Dataset.from_tensors(tensor).repeat(num_epochs)`.\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/input.py:199: QueueRunner.__init__ (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","To construct input pipelines, use the `tf.data` module.\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/input.py:199: add_queue_runner (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","To construct input pipelines, use the `tf.data` module.\n","WARNING:tensorflow:From <ipython-input-6-6bb16eb19fc0>:25: shuffle_batch (from tensorflow.python.training.input) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Queue-based input pipelines have been replaced by `tf.data`. Use `tf.data.Dataset.shuffle(min_after_dequeue).batch(batch_size)`.\n","[INFO] RESTORED\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/saver.py:1276: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use standard file APIs to check for files with this prefix.\n","INFO:tensorflow:Restoring parameters from /content/drive/My Drive/Colab_ML/PokeGan/model/newPokemon/1950\n","WARNING:tensorflow:From <ipython-input-9-5018e73ad028>:50: start_queue_runners (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","To construct input pipelines, use the `tf.data` module.\n","total training sample num:352\n","batch size: 64, batch num per epoch: 5, epoch num: 5000\n","start training...\n","epochh\n","batch\n","batch\n","batch\n","batch\n","batch\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:root:Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n"],"name":"stderr"},{"output_type":"stream","text":["train:[1950],d_loss:-35.540665,g_loss:18.063749\n","epochh\n","batch\n","batch\n","batch\n","batch\n","batch\n","train:[1951],d_loss:-25.432119,g_loss:12.724567\n","epochh\n","batch\n","batch\n","batch\n","batch\n","batch\n","train:[1952],d_loss:-32.875450,g_loss:14.857151\n","epochh\n","batch\n","batch\n","batch\n","batch\n","batch\n","train:[1953],d_loss:-34.828072,g_loss:17.929506\n","epochh\n","batch\n","batch\n","batch\n","batch\n","batch\n","train:[1954],d_loss:-32.977459,g_loss:18.150337\n","epochh\n","batch\n","batch\n","batch\n","batch\n","batch\n","train:[1955],d_loss:-29.344603,g_loss:14.836653\n","epochh\n","batch\n","batch\n","batch\n","batch\n","batch\n","train:[1956],d_loss:-33.911221,g_loss:17.765453\n","epochh\n","batch\n","batch\n","batch\n","batch\n","batch\n","train:[1957],d_loss:-20.486084,g_loss:5.785151\n","epochh\n","batch\n","batch\n","batch\n","batch\n","batch\n","train:[1958],d_loss:-33.549690,g_loss:17.576693\n","epochh\n","batch\n","batch\n","batch\n","batch\n","batch\n","train:[1959],d_loss:-32.099670,g_loss:15.916659\n","epochh\n","batch\n","batch\n","batch\n","batch\n","batch\n","train:[1960],d_loss:-34.446407,g_loss:18.223806\n","epochh\n","batch\n","batch\n","batch\n","batch\n","batch\n","train:[1961],d_loss:-35.774475,g_loss:18.069057\n","epochh\n","batch\n","batch\n","batch\n","batch\n","batch\n","train:[1962],d_loss:-31.989849,g_loss:17.146427\n","epochh\n","batch\n","batch\n","batch\n","batch\n","batch\n","train:[1963],d_loss:-34.969250,g_loss:17.815315\n","epochh\n","batch\n","batch\n","batch\n","batch\n","batch\n","train:[1964],d_loss:-35.260582,g_loss:18.345512\n","epochh\n","batch\n","batch\n","batch\n","batch\n","batch\n","train:[1965],d_loss:-32.633980,g_loss:17.896080\n","epochh\n","batch\n","batch\n","batch\n","batch\n","batch\n","train:[1966],d_loss:-28.031425,g_loss:16.336178\n","epochh\n","batch\n","batch\n","batch\n","batch\n","batch\n","train:[1967],d_loss:-33.125103,g_loss:17.106335\n","epochh\n","batch\n","batch\n","batch\n","batch\n","batch\n","train:[1968],d_loss:-35.060997,g_loss:17.976902\n","epochh\n","batch\n","batch\n","batch\n","batch\n","batch\n","train:[1969],d_loss:-33.150452,g_loss:16.117420\n","epochh\n","batch\n","batch\n","batch\n","batch\n","batch\n","train:[1970],d_loss:-32.268272,g_loss:17.892822\n","epochh\n","batch\n","batch\n","batch\n","batch\n","batch\n","train:[1971],d_loss:-34.646816,g_loss:17.453068\n","epochh\n","batch\n","batch\n","batch\n","batch\n","batch\n","train:[1972],d_loss:-35.415401,g_loss:18.132284\n","epochh\n","batch\n","batch\n","batch\n","batch\n","batch\n","train:[1973],d_loss:-34.287384,g_loss:18.297005\n","epochh\n","batch\n","batch\n","batch\n","batch\n","batch\n","train:[1974],d_loss:-34.212654,g_loss:18.026981\n","epochh\n","batch\n","batch\n","batch\n","batch\n","batch\n","train:[1975],d_loss:-29.238455,g_loss:12.535556\n","epochh\n","batch\n","batch\n","batch\n","batch\n","batch\n","train:[1976],d_loss:-20.070192,g_loss:17.951485\n","epochh\n","batch\n","batch\n","batch\n","batch\n","batch\n","train:[1977],d_loss:-31.921900,g_loss:17.884398\n","epochh\n","batch\n","batch\n","batch\n","batch\n","batch\n","train:[1978],d_loss:-34.754578,g_loss:17.889200\n","epochh\n","batch\n","batch\n","batch\n","batch\n","batch\n","train:[1979],d_loss:-32.686024,g_loss:17.730118\n","epochh\n","batch\n","batch\n","batch\n","batch\n","batch\n","train:[1980],d_loss:-17.517302,g_loss:11.185102\n","epochh\n","batch\n","batch\n","batch\n","batch\n","batch\n","train:[1981],d_loss:-32.981228,g_loss:17.465387\n","epochh\n","batch\n","batch\n","batch\n","batch\n","batch\n","train:[1982],d_loss:-19.937834,g_loss:12.244325\n","epochh\n","batch\n","batch\n","batch\n","batch\n","batch\n","train:[1983],d_loss:-29.646128,g_loss:17.730556\n","epochh\n","batch\n","batch\n","batch\n","batch\n","batch\n","train:[1984],d_loss:-33.337582,g_loss:17.413935\n","epochh\n","batch\n","batch\n","batch\n","batch\n","batch\n","train:[1985],d_loss:-35.688862,g_loss:18.317524\n","epochh\n","batch\n","batch\n","batch\n","batch\n","batch\n","train:[1986],d_loss:-31.523205,g_loss:17.575474\n","epochh\n","batch\n","batch\n","batch\n","batch\n","batch\n","train:[1987],d_loss:-35.302094,g_loss:18.484135\n","epochh\n","batch\n","batch\n","batch\n","batch\n","batch\n","train:[1988],d_loss:-34.592312,g_loss:17.528942\n","epochh\n","batch\n","batch\n","batch\n","batch\n","batch\n","train:[1989],d_loss:-35.329994,g_loss:18.260887\n","epochh\n","batch\n","batch\n","batch\n","batch\n","batch\n","train:[1990],d_loss:-34.548832,g_loss:17.816261\n","epochh\n","batch\n","batch\n","batch\n","batch\n","batch\n","train:[1991],d_loss:-32.781574,g_loss:17.926128\n","epochh\n","batch\n","batch\n","batch\n","batch\n","batch\n","train:[1992],d_loss:-34.076996,g_loss:16.789474\n","epochh\n","batch\n","batch\n","batch\n","batch\n","batch\n","train:[1993],d_loss:-34.403229,g_loss:17.056522\n","epochh\n","batch\n","batch\n","batch\n","batch\n","batch\n","train:[1994],d_loss:-36.075996,g_loss:18.163095\n","epochh\n","batch\n","batch\n","batch\n","batch\n","batch\n","train:[1995],d_loss:-34.923836,g_loss:18.081900\n","epochh\n","batch\n","batch\n","batch\n","batch\n","batch\n","train:[1996],d_loss:-29.927134,g_loss:12.428099\n","epochh\n","batch\n","batch\n","batch\n","batch\n","batch\n","train:[1997],d_loss:-34.458656,g_loss:17.206306\n","epochh\n","batch\n","batch\n","batch\n","batch\n","batch\n","train:[1998],d_loss:-24.392496,g_loss:17.229424\n","epochh\n","batch\n","batch\n","batch\n","batch\n","batch\n","train:[1999],d_loss:-31.239731,g_loss:17.317654\n","epochh\n","batch\n","batch\n","batch\n","batch\n","batch\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:root:Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n"],"name":"stderr"},{"output_type":"stream","text":["train:[2000],d_loss:-23.439814,g_loss:14.598978\n","epochh\n","batch\n","batch\n","batch\n","batch\n","batch\n","train:[2001],d_loss:-33.678207,g_loss:17.873051\n","epochh\n","batch\n","batch\n","batch\n","batch\n","batch\n","train:[2002],d_loss:-34.953484,g_loss:18.131298\n","epochh\n","batch\n","batch\n","batch\n","batch\n","batch\n","train:[2003],d_loss:-15.178753,g_loss:13.172270\n","epochh\n","batch\n","batch\n","batch\n","batch\n","batch\n","train:[2004],d_loss:-35.029541,g_loss:17.844116\n","epochh\n","batch\n","batch\n","batch\n","batch\n","batch\n","train:[2005],d_loss:-34.842716,g_loss:17.445408\n","epochh\n","batch\n","batch\n","batch\n","batch\n","batch\n","train:[2006],d_loss:-34.787582,g_loss:17.997244\n","epochh\n","batch\n","batch\n","batch\n","batch\n","batch\n","train:[2007],d_loss:-32.986702,g_loss:17.761524\n","epochh\n","batch\n","batch\n","batch\n","batch\n","batch\n","train:[2008],d_loss:-30.053185,g_loss:18.050495\n","epochh\n","batch\n","batch\n","batch\n","batch\n","batch\n","train:[2009],d_loss:-32.542393,g_loss:18.278393\n","epochh\n","batch\n","batch\n","batch\n","batch\n","batch\n","train:[2010],d_loss:-33.890018,g_loss:15.673803\n","epochh\n","batch\n","batch\n","batch\n","batch\n","batch\n","train:[2011],d_loss:-34.754997,g_loss:17.991116\n","epochh\n","batch\n","batch\n","batch\n","batch\n","batch\n","train:[2012],d_loss:-31.475212,g_loss:16.884361\n","epochh\n","batch\n","batch\n","batch\n","batch\n","batch\n","train:[2013],d_loss:-15.731127,g_loss:16.511150\n","epochh\n","batch\n","batch\n","batch\n"],"name":"stdout"},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-11-689fc2681c8c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;34m\"__main__\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m<ipython-input-9-5018e73ad028>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m()\u001b[0m\n\u001b[1;32m     62\u001b[0m             \u001b[0mtrain_noise\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muniform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1.0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1.0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_dim\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md_iters\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m                 \u001b[0mtrain_image\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m                 \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md_clip\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    948\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    949\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 950\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    951\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    952\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1171\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1172\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1173\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1174\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1175\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1348\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1349\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1350\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1351\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1352\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1354\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1355\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1356\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1357\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1358\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1339\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1340\u001b[0m       return self._call_tf_sessionrun(\n\u001b[0;32m-> 1341\u001b[0;31m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[1;32m   1342\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1343\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1427\u001b[0m     return tf_session.TF_SessionRun_wrapper(\n\u001b[1;32m   1428\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1429\u001b[0;31m         run_metadata)\n\u001b[0m\u001b[1;32m   1430\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1431\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_tf_sessionprun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"cell_type":"markdown","metadata":{"id":"-bykijLtCv-T","colab_type":"text"},"source":[""]}]}